#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os, sys, array, argparse, logging, time, datetime

startTime = time.time()
app = os.path.basename(__file__)
max_window = 1000000

# Beautiful --help
class AParser(argparse.ArgumentParser) :
  def help_message(name = None) :
    print ''
    print 'Usage:'
    print '  ./' + app + ' -t [input bam-file] [Optional arguments]'
    print ''
    print 'Optional arguments:'
    print '  -t,  --input      Path to `input.bam` file'
    print '  -o,  --output     Output file name'
    print '  -l,  --log        Output log file name'
    print '  -w,  --window     Window size (in bp). Default: 200'
    print '  -f,  --fragment   Fragment size (in bp). Default: 250'
    print '  -e,  --gms        Proportion of effective genome length; has to be in [0.0, 1.0]. Default: auto'
    print '  -g,  --gap        Gap size shows how many bases could be skipped. Default: 200'
    print '  -p,  --pvalue     P-value; has to be in [0.0, 1.0]. Default: 0.2'
    print '  -x,  --threshold  Island score threshold. Default: auto'
    print ''
    print 'Examples:'
    print '  ./' + app + ' input.bam'
    print '  ./' + app + ' -t input.bam -c control.bam -w 100 -g 100 -e 0.845'
    print ''
  def error(self, message):
    sys.stderr.write('Error:\n  %s\n' % message)
    self.help_message()
    sys.exit(2)

# ---------------------------------------------------------------------------- #

parser = AParser()
parser.add_argument('-t', '--track',     type = argparse.FileType('r'))
parser.add_argument('-o', '--output',    type = argparse.FileType('w'))
parser.add_argument('-l', '--log',       default = None)
parser.add_argument('-c', '--control',   default = None, type = argparse.FileType('r'))
parser.add_argument('-w', '--window',    default = 200, type = int)
parser.add_argument('-f', '--fragment',  default = 'auto')
parser.add_argument('-e', '--gms',       default = 'auto')
parser.add_argument('-g', '--gap',       default = 200, type = int)
parser.add_argument('-p', '--pvalue',    default = 0.2, type = float)
parser.add_argument('-x', '--threshold', default = 'auto')

if len(sys.argv) == 1 :
  parser.help_message()
  sys.exit(2)

if len(sys.argv) == 2 :
  args = parser.parse_args(['-t', sys.argv[1]])
else :
  args = parser.parse_args()

if args.track.name[-4:] == '.bam' :
  logfile = args.track.name[0:-4] + '_output.log'
  resultf = args.track.name[0:-4] + '_peaks.bed'
else :
  logfile = args.track.name + '_output.log'
  resultf = args.track.name + '_peaks.bed'

if args.log : logfile = args.log
if args.output : resultf = args.output.name #  + '_peaks.bed'

logging.basicConfig(filename = logfile, level = logging.DEBUG, format = '%(message)s')
logging.info('=' * 80)
logging.info('Date: ' + datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d %H:%M:%S'))
logging.info('Command:')

cmd = ['--track ' + str(args.track.name)]

try :
  fragmentsize = float(args.fragment)
except :
  fragmentsize = 0

try :
  threshold = float(args.threshold)
except :
  threshold = 0

if args.control : cmd.append('--control ' + str(args.control.name))
if args.output  : cmd.append('--output ' + str(args.output.name))
if args.log     : cmd.append('--log ' + str(args.log))
if fragmentsize > 0 : cmd.append('--fragment ' + str(fragmentsize))

try :
  gms = float(args.gms)
except :
  gms = 0

gap_size = max(args.gap, args.window)
cmd.extend([
  '--window ' + str(args.window),
  '--gms ' + str(args.gms),
  '--gap ' + str(gap_size),
  '--pvalue ' + str(args.pvalue),
  '--threshold ' + str(args.threshold)
])

logging.info(sys.argv[0] + ' \\\n  ' + (' \\\n  ').join(cmd))
logging.info('')
# Source:
# https://github.com/JohnLonginotto/pybam

import zlib
import struct
import itertools
import subprocess

class bgunzip:
    def __init__(self,file_handle,blocks_at_a_time=50):
        ## First we init some basic things so that we will fill up in a sec.
        self.blocks_at_a_time = blocks_at_a_time
        self.bytes_read = 0
        self.rows = 0
        self.chromosome_names = []
        self.chromosome_lengths = []
        self.chromosomes_from_header = []
        self.file_handle = file_handle

        # Now we init the generator that, when iterated, will return some chunk of uncompress data.
        self.generator = self._generator()

        # We grab the first chunk, which is more than enough to contain all the header information, and parse the binary header:
        first_chunk = next(self.generator)
        if first_chunk[:4] != 'BAM\1': print 'ERROR: This doesnt look like a bam file to me :/'; exit()
        length_of_header = struct.unpack('<i',first_chunk[4:8])[0]
        self.header_text = struct.unpack(str(length_of_header)+'s',first_chunk[8:8+length_of_header])[0]
        self.number_of_reference_sequences = struct.unpack('<i',first_chunk[8+length_of_header:12+length_of_header])[0]
        rs = length_of_header + 12
        for _ in range(self.number_of_reference_sequences):
            l_name = struct.unpack('<l',first_chunk[rs:rs+4])[0]
            name, l_ref = struct.unpack('<%dsl' % l_name, first_chunk[rs+4:rs+l_name+8]) # disgusting.
            self.chromosome_names.append(name[:-1]) # We dont need the NUL byte.
            self.chromosome_lengths.append(l_ref)
            rs += 8 + l_name
        self.original_binary_header = buffer(first_chunk[:rs])
        self.left_overs = first_chunk[rs:] # bgzip doesnt care about where it drops the division between blocks, so we end up with some
                                           # bytes in the first block that contain read data, not header data.
        for line in self.header_text.split('\n'):
            if line.startswith('@SQ\tSN:'):
                self.chromosomes_from_header.append(line.split('\t')[1][3:]) # God I hope no programs put spaces in the headers instead of tabs..
        if self.chromosomes_from_header != self.chromosome_names:
            print 'ERROR: For some reason, and I have no idea why, the BAM file stores the chromosome name in two locations, the '
            print '       ASCII text header we all know and love, viewable with samtools view -H, and another special binary header'
            print '       which is used to translate the chromosome refID (a number) into a chromosome RNAME when you do bam -> sam.'
            print '       These two headers should always be the same, but apparently someone has messed that up. #YOLO\n'
            print 'Your ASCII header looks like:\n' + self.header_text
            print '\nWhile your binary header has the following chromosomes:'
            print self.chromosome_names
            exit()

        # Now we have the header data stored, but our first call to the generator gave us a block of uncompressed data back that contained way more than
        # just the header data alone. We want this class to be a generator that, on every request, hands back READ data in BAM format uncompressed, starting
        # from the first read, so in order to do that, we need to create a new generator-shim that just regurgitates what was left over from the header parse
        # the first time its called, then uses whatever self.generator would give on all subsequent tries after that.
        # This is how we do that:
        self._iterator = itertools.chain([self.left_overs],self.generator)

    # And this tells python the class is a generator:
    def __iter__(self): return self 
    def next(self): return next(self._iterator)

    def _generator(self):
        try:
            if type(self.file_handle) == str: p = subprocess.Popen(['pigz','-dc',self.file_handle], stdout=subprocess.PIPE)
            elif type(self.file_handle) == file: p = subprocess.Popen(['pigz','-dc'],stdin=self.file_handle, stdout=subprocess.PIPE)
            else: print 'ERROR: I do not know how to open and read from "' + str(self.file_handle) + '"'; exit()
            self.file_handle = p.stdout
            #sys.stderr.write('Using pigz!\n')
        except OSError:
            try:
                if type(self.file_handle) == str:    p = subprocess.Popen(['gzip','--stdout','--decompress','--force',self.file_handle]       , stdout=subprocess.PIPE)
                elif type(self.file_handle) == file: p = subprocess.Popen(['gzip','--stdout','--decompress','--force'], stdin=self.file_handle, stdout=subprocess.PIPE)
                else: print 'ERROR: I do not know how to open and read from "' + str(self.file_handle) + '"'; exit()
                self.file_handle = p.stdout
                #sys.stderr.write('Using gzip!\n')
            except OSError:
                sys.stderr.write('Using internal Python...\n') # We will end up using the python code below. It is faster than the gzip module, but
                                                               # due to how slow Python's zlib module is, it will end up being about 2x slower than pysam.
        data = self.file_handle.read(655360)
        self.bytes_read += 655360
        cache = []
        blocks_left_to_grab = self.blocks_at_a_time
        bs = 0
        checkpoint = 0
        #pool = Pool(processes=3) 
        #def decompress(data): return zlib.decompress(data, 47) # 47 == zlib.MAX_WBITS|32
        decompress = zlib.decompress
        while data:
            if len(data) - bs < 65536:
                data = data[bs:] + self.file_handle.read(35536)
                self.bytes_read += len(data) - bs
                bs = 0

            magic = data[bs:bs+4]
            if not magic: break # a child's heart
            if magic != "\x1f\x8b\x08\x04":
                if magic == 'BAM\1':
                    # The user has passed us already unzipped data, or we're reading from pigz/gzip :)
                    while data:
                        yield data
                        data = self.file_handle.read(35536)
                        self.bytes_read += len(data)
                    raise StopIteration
                elif magic == 'SQLi': print 'OOPS: You have used an SQLite database as your input BAM file!!'; exit()
                else:                 print 'ERROR: The input file is not in a format I understand :('       ; exit()

            try:
                # The gzip format allows compression containers to store metadata about whats inside them. bgzip uses this
                # to encode the virtual file pointers, final decompressed block size, crc checks etc - however we really dont
                # care -- we just want to unzip everything as quickly as possible. So instead of 'following the rules', and parsing this metadata safely,
                # we try to take a short-cut and jump right to the good stuff, and only if that fails we go the long-way-around and parse every bit of metadata properly:

                #cache.append(decompress(data[bs+18:more_bs-8])) ## originally i stored uncompressed data in a list and used map() to decompress in multiple threads. Was not faster.
                #new_zipped_data = data[bs:more_bs]              ## originally i decompressed the data with a standard zlib.decompress(data,47), headers and all. Was slower.
                more_bs = bs + struct.unpack("<H", data[bs+16:bs+18])[0] +1
                cache.append(decompress(data[bs+18:more_bs-8],-15))
                bs = more_bs
            except: ## zlib doesnt have a nice exception for when things go wrong. just "error"
                sys.stderr.write('INFO: Odd bzgip block detected! The author of pybam didnt think this would ever happen... please could you let me know?')
                header_data = magic + data[bs+4:bs+12]
                header_size = 12
                extra_len = struct.unpack("<H", header_data[-2:])[0]
                while header_size-12 < extra_len:
                    header_data += data[bs+12:bs+16]
                    subfield_id = header_data[-4:-2]
                    subfield_len = struct.unpack("<H", header_data[-2:])[0]
                    subfield_data = data[bs+16:bs+16+subfield_len]
                    header_data += subfield_data
                    header_size += subfield_len + 4
                    if subfield_id == 'BC': block_size = struct.unpack("<H", subfield_data)[0]
                raw_data = data[bs+16+subfield_len:bs+16+subfield_len+block_size-extra_len-19]
                crc_data = data[bs+16+subfield_len+block_size-extra_len-19:bs+16+subfield_len+block_size-extra_len-19+8] # I have left the numbers in verbose, because the above try is the optimised code.
                bs = bs+16+subfield_len+block_size-extra_len-19+8
                zipped_data = header_data + raw_data + crc_data
                cache.append(decompress(zipped_data,47)) # 31 works the same as 47.
                # Although the following in the bgzip code from biopython, its not needed if you let zlib decompress the whole zipped_data, header and crc, because it checks anyway (in C land)
                # I've left the manual crc checks in for documentation purposes:
                expected_crc = crc_data[:4]
                expected_size = struct.unpack("<I", crc_data[4:])[0]
                if len(unzipped_data) != expected_size: print 'ERROR: Failed to unpack due to a Type 1 CRC error. Could the BAM be corrupted?'; exit()
                crc = zlib.crc32(unzipped_data)
                if crc < 0: crc = struct.pack("<i", crc)
                else:       crc = struct.pack("<I", crc)
                if expected_crc != crc: print 'ERROR: Failed to unpack due to a Type 2 CRC error. Could the BAM be corrupted?'; exit()

            blocks_left_to_grab -= 1
            if blocks_left_to_grab == 0:
                yield ''.join(cache)
                cache = []
                blocks_left_to_grab = self.blocks_at_a_time
        self.file_handle.close()
        if cache != '': yield ''.join(cache)

class Island_threshold :
	def __init__(self, total_tags, windowSize, gapSize, window_pvalue, genomeLength, bin_size, e_value_threshold):
		self.gap_size = gapSize/windowSize;
		self.genome_length = int(ceil(float(genomeLength)/windowSize));
		self.average = (total_tags * 1.0 / genomeLength) * windowSize;
		self.bin_size = bin_size;
		self.max_index = max (500, int(2*self.average));
		self.poisson_value = [];
		self.window_score = [];
		for index in xrange(self.max_index):
			prob = scipy.stats.poisson.pmf(index, self.average);
			self.poisson_value.append(prob);
			if ( index < self.average):
				self.window_score.append(0);
			else:
				self.window_score.append(-log(prob) if prob > 0 else 1000);
		self.max_index = len(self.poisson_value);
		self.min_tags_in_window = 0;
		sf = 1 ;
		while (sf > window_pvalue ):
			sf -= self.poisson_value[self.min_tags_in_window]
			self.min_tags_in_window += 1;
		self.gap_contribution = self.gap_factor();
		self.boundary_contribution = self.boundary();
		self.cumulative=[];
		prob = self.boundary_contribution * self.poisson_value[self.min_tags_in_window];
		score = -log(self.poisson_value[self.min_tags_in_window]);
		scaled_score = int(round(score/self.bin_size));
		self.island_expectation =[0] * (scaled_score+1);
		self.island_expectation[scaled_score] = prob*self.genome_length;
		self.island_expectation[0] = self.boundary_contribution*self.genome_length/self.gap_contribution;
		self.threshold = self.find_island_threshold(e_value_threshold)

	def single_gap_factor(self):
		my_gap_factor=0;
		for i in xrange(self.min_tags_in_window):
			my_gap_factor +=self.poisson_value[i];
		return my_gap_factor;

	def gap_factor(self):
		if self.gap_size == 0 : return 1
		i = 1;
		gap_contribution = 1;
		my_gap_factor = self.single_gap_factor();
		for i in range(1, self.gap_size+1): gap_contribution += pow(my_gap_factor, i);
		return gap_contribution;

	def boundary(self):
		temp = self.single_gap_factor();
		temp = pow(temp, self.gap_size+1); 
		return temp*temp; # start & end 

	def background_island_expectation (self, scaled_score):
		current_max_scaled_score = len(self.island_expectation)-1;
		if scaled_score > current_max_scaled_score:
			#index is the scaled_score
			for index in range(current_max_scaled_score + 1, scaled_score+1):
				temp=0.0;
				#i is the number of tags in the added window
				i = self.min_tags_in_window;
				while ( int(round(index - self.window_score[i]/self.bin_size))>=0):
				#while ( (index - self.window_scaled_score[i])>=0):
					temp += self.poisson_value[i]* self.island_expectation[int(round(index - self.window_score[i]/self.bin_size))];
					#temp += self.poisson_value[i]* self.island_expectation[index - self.window_scaled_score[i]];
					i += 1;
				temp *= self.gap_contribution;
				self.island_expectation.append(temp);
				#print index, temp, self.island_expectation[index];
		return self.island_expectation[scaled_score];

	def find_island_threshold(self, e_value_threshold):
		threshold = .0000001*e_value_threshold;
		current_scaled_score = len (self.island_expectation) - 1;
		current_expectation = self.island_expectation[-1];
		assert (current_expectation == self.island_expectation[current_scaled_score]);
		interval = int(1/self.bin_size);
		if len(self.island_expectation) > interval:
			partial_cumu = sum(self.island_expectation[-interval: -1])
		else:
			partial_cumu = sum(self.island_expectation)
		while ( partial_cumu > threshold or  partial_cumu <1e-100):
			current_scaled_score += interval;
			current_expectation=self.background_island_expectation(current_scaled_score);
			if len(self.island_expectation) > interval:
				partial_cumu = sum(self.island_expectation[-interval: -1])
			else:
				partial_cumu = sum(self.island_expectation)

		# generate_cumulative_dist
		self.cumulative=[0]*len(self.island_expectation);
		partial_sum = 0.0
		for index in range(1, len(self.island_expectation)+1):
			complimentary = len(self.island_expectation) - index;
			partial_sum += self.island_expectation[complimentary]; # The end is outside of the index
			self.cumulative[complimentary]=partial_sum;

		for index in xrange(len(self.cumulative)):
			if self.cumulative[index]<=e_value_threshold:
				score_threshold = index*self.bin_size;
				break;
		return score_threshold;
# ---------------------------------------------------------------------------- #
species = {
  'anoGam1': [62725911,59568033,53272125,48795086,41284009,22145176,15363],
  'apiMel2': [321143811,25433307,14233499,14191905,13312070,12413357,11790680,10993160,10665743,9968276,9828392,9757938,8966624,8846036,8017760,7326077,5608962],
  'braFlo1': [926371504,15083],
  'caePb2': [194283334],
  'cb3': [20608032,16004101,15290274,14512975,13544562,11274843,7311690,3509021,2554181,2252910,864856,751081,14420],
  'ce11': [20924180,17718942,17493829,15279421,15072434,13783801,13794],
  'caeJap1': [156378573],
  'caeRem3': [149111736],
  'dp3': [30711475,19738957,14308685,12499574,11635473,9190824,9052427,6620765,6604477,6604331,5302587,2686958,2329291,1468299,1217433,733150,374547],
  'droSim1': [27517382,22553184,22036055,19596830,17042790,15797150,5698898,3178526,2996586,1452968,1307089,1049610,949497,909653,134295,100575,84659,14972],
  'droYak2': [28832112,28119190,24197627,22324452,21770863,21139217,4797643,4064425,3774259,3277457,1802292,1374474,911842,894407,720513,261230,172766,114151,67238,31700,16019],
  'eboVir3': [18957],
  'equCab2': [185838109,124114077,120857687,119479920,117461955,108569075,99680356,98542428,94057673,93904894,91571448,87365405,84719076,83980604,83561422,82527541,80757907,64166202,61308211,59975221,57723302,55726280,49946797,46749900,46177339,42578167,41866177,39960074],
  'fr2': [400509343,16447],
  'hg19': [249250621,243199373,198022430,191154276,180915260,171115067,159138663,155270560,146364022,141213431,135534747,135006516,133851895,115169878,107349540,102531392,90354753,81195210,78077248,63025520,59373566,59128983,51304566,48129895,4928567,4833398,4795371,4683263],
  'monDom5': [748055161,541556283,527952102,435153693,312544902,304825324,292091736,260857928,103241611,79335909,17079],
  'mm10': [195471971,182113224,171031299,160039680,156508116,151834684,149736546,145441459,130694993,129401213,124902244,124595110,122082543,120421639,120129022,104043685,98207768,94987271,91744698,90702639,61431566,953012,336933,259875,241735,227966,207968,206961],
  'ponAbe2': [229942017,202140232,198332218,183952662,174210431,157549271,156195299,153482349,136387465,135191526,135000294,133410057,132107971,117095149,113028656,108868599,99152023,94050890,77800216,73212453,72422247,62736349,60714840,48394510,46535552,39000292,35968885,23176937],
  'ponAbe2': [229942017,202140232,198332218,183952662,174210431,157549271,156195299,153482349,136387465,135191526,135000294,133410057,132107971,117095149,113028656,108868599,99152023,94050890,77800216,73212453,72422247,62736349,60714840,48394510,46535552,39000292,35968885,23176937],
  'priPac1': [174852139],
  'sacCer3': [1531933,1091291,1090940,1078177,948066,924431,813184,784333,745751,666816,576874,562643,439888,316620,270161,230218,85779],
  'susScr2': [295529705,148510138,145235301,140133492,136409062,136254946,134541103,132468591,125871292,123599780,123305171,119985671,100516970,79814395,77435658,66736929,64395339,57431344,54309914,16770],
  'fr2': [400509343,16447],
  'tetNig2': [107808587,22981688,21591555,15489435,13390619,13302670,13272281,12622881,12136232,11954808,11693588,11077504,10554956,10512681,10246949,9874776,9031048,7320470,7272499,7024381,5834722,3798727,3311323,3234215,2082209,1180980,16462],
  'hg18': [247249719,242951149,199501827,191273063,180857866,170899992,158821424,154913754,146274826,140273252,135374737,134452384,132349534,114142980,106368585,100338915,88827254,78774742,76117153,63811651,62435964,57772954,49691432,46944323,4731698,4565931,2617613,1875562]
}

spnames = {
  'anoGam1':'Anopheles gambiae',
  'apiMel2':'Apis mellifera',
  'braFlo1':'Branchiostoma floridae',
  'caePb2':'Caenorhabditis brenneri',
  'cb3':'Caenorhabditis briggsae',
  'ce11':'Caenorhabditis elegans',
  'caeJap1':'Caenorhabditis japonica',
  'caeRem3':'Caenorhabditis remanei',
  'dp3':'Drosophila pseudoobscura',
  'droSim1':'Drosophila simulans',
  'droYak2':'Drosophila yakuba',
  'eboVir3':'Ebola virus',
  'equCab2':'Equus caballus',
  'fr2':'Takifugu rubripes',
  'hg19':'Homo sapiens',
  'monDom5':'Monodelphis domestica',
  'mm10':'Mus musculus',
  'ponAbe2':'Pongo pygmaeus abelii',
  'priPac1':'Pristionchus pacificus',
  'sacCer3':'Saccharomyces cerevisiae',
  'susScr2':'Sus scrofa',
  'tetNig2':'Tetraodon nigroviridis',
  'hg18':'Homo sapiens'
}

# ---------------------------------------------------------------------------- #
def define_specie(info) :
  vote = {}
  total = 1
  for c in info :
    total += info[c]['Unique reads']

  for c in info :
    dists = []
    for table in species :
      for chr in species[table]:
        dists.append([pow(chr - info[c]['Length'], 2), table])
    v = sorted(dists, key=lambda e: e[0])
    for k in [0,1,2] :
      if v[k][1] not in vote : vote[v[k][1]] = 0
      vote[v[k][1]] += float(3 - k) * info[c]['Unique reads']/total
  code = max(vote, key = vote.get)
  return [code, spnames[code]]


# ---------------------------------------------------------------------------- #
def parser(data_generator):
  chunk = next(data_generator)
  CtoPy = { 'A':'<c', 'c':'<b', 'C':'<B', 's':'<h', 'S':'<H', 'i':'<i', 'I':'<I' }
  py4py = { 'A':  1,  'c':  1,  'C':  1,  's':  2,  'S':  2,  'i':  4 , 'I':  4  }
  dna = '=ACMGRSVTWYHKDBN'
  cigar_codes = 'MIDNSHP=X'
  from array import array
  from struct import unpack
  p = 0
  while True:
    try:
        while len(chunk) < p+36: chunk = chunk[p:] + next(data_generator); p = 0
        block_size,refID,pos,l_read_name,mapq,bin_,n_cigar_op,flag,l_seq                          = unpack('<iiiBBHHHi'   ,chunk[p:p+24])
        while len(chunk) < p + 4 + block_size: chunk = chunk[p:] + next(data_generator); p = 0
    except StopIteration: break
    end = p + block_size + 4
    p += 36
    qname = chunk[p:p+l_read_name-1]
    p = end
    yield pos,refID,flag,l_seq,qname


# ---------------------------------------------------------------------------- #
def chrsort(s) :
  s = s.lower()  
  if s[0:3] == 'chr' : 
    s = s.replace('chr','')
    if unicode(s, 'utf-8').isnumeric() : return int(s)
    return 40
  return 999


# ---------------------------------------------------------------------------- #
def beautiful_table(data, cols = 3) :
  t = lambda A : [list(x) for x in zip(*A)] # Транспонирование
  r = (len(data) - len(data)%cols)/cols + 1 # Число строк в столбце
  T = []
  for i in range(0, len(data), r):
    col = data[i:i + r]
    while len(col) <= r : 
      col.append(len(col[0]) * [' '])
    col = t(col)
    siz = map(lambda c : max(map(lambda x : len(str(x)), c)), col)
    # ¯\_(ツ)_/¯
    for i in range(len(col)) :
      k = map(lambda x : str(x) + (siz[i] - len(str(x)) + 1) * " ", col[i])
      T.append(k)
    T.append(['  |  '] * r)
  if len(T) == 0 : return ''
  T = map(lambda x : ('').join(x), t(T[0:-1]))
  V = (len(T[0])) * '-' + '\n'
  return V + ('\n').join(T) + '\n' + V


# ---------------------------------------------------------------------------- #
def get_gms(info, length, gms) :
  if gms > 0 and gms <= 1 :
    msg = "Using custom effective proportion: {}"
    logging.info(msg.format(gms))
    return gms
  
  specie, specie_name = define_specie(info)
  GMS = {}
  GMS['hg19'] = [[20,0.697969],[25,0.750921],[30,0.782328],[40,0.824712],[60,0.867066],[80,0.882649],[100,0.889473],[120,0.893435],[140,0.896156]]
  GMS['mm10'] = [[25,0.766128],[30,0.790964],[40,0.822389],[60,0.857177],[80,0.875752],[100,0.88708],[120,0.894755],[140,0.900449]]

  # Default value
  if specie not in GMS : 
    gms = 0.77
    msg = "Using default effective proportion: {}"
    logging.info(msg.format(gms))
    return gms

  # Approximation
  if GMS[specie][0][0] > length :
    gms = GMS[specie][0][1]
  if GMS[specie][-1][0] < length :
    gms = GMS[specie][-1][1]
  
  for e in range(0, len(GMS[specie]) - 1) :
    a1, v1 = GMS[specie][e]
    a2, v2 = GMS[specie][e + 1]
    if a2 >= length and a1 <= length :
      # Интерполяция
      # (a2 - a1)/(v2 - v1) == (length - a1)/(x - v1)
      gms = (length - a1) * (v2 - v1)/(a2 - a1) + v1

  # ...
  msg = "Using default effective proportion for {}: {}"
  logging.info(msg.format(specie_name, gms))
  return gms


# ---------------------------------------------------------------------------- #
def count_lambda(unique_reads_count, wsize, effective_length):
  plambda = float(wsize) * float(unique_reads_count) / float(effective_length)
  msg = "Average density of reads per {} bp window: {}"
  logging.info(msg.format(wsize, round(plambda, 2)))
  return plambda


# ---------------------------------------------------------------------------- #
def preparation(track, gms) :
  length_hist = {}
  distance = { 'sum' : 0, 'count' : 0 }
  reads = { 0 : 0, 16 : 0 }
  info = {}
  data = {}

  for read in parser(track) :
    pos, chr, strand_key, l_seq, qname = read
    if chr < 0 or chr > len(track.chromosome_names) : continue
    c = track.chromosome_names[chr]
    if l_seq not in length_hist : length_hist[l_seq] = 0
    length_hist[l_seq] += 1

    # New chromosome name:
    if c not in info : 
      firsts = 0
      data[c] = array.array('l', [])
      info[c] = {
        'Length' : track.chromosome_lengths[chr],
        'Unique reads' : 0,
        'Total reads'  : 0,
        'Names' : {}
      }

    firsts += 1
    if firsts < 300 :
      if strand_key in [99,147,163,83] : # check paired reads
        if qname not in info[c]['Names'] : 
          info[c]['Names'][qname] = pos
        else :
          dist = abs(info[c]['Names'][qname] - pos)
          if dist > 0 :
            distance['sum'] += dist
            distance['count'] += 1

    info[c]['Total reads'] += 1
    if strand_key not in reads : reads[strand_key] = 0
    reads[strand_key] += 1

    prev_key = 'Previous ' + str(strand_key)
    ignore = False
    if prev_key in info[c] :
      if info[c][prev_key] == pos : ignore = True

    if ignore == False :
      info[c][prev_key] = pos
      data[c].append(1000 * pos + strand_key)
      info[c]['Unique reads'] += 1
    # <- if
  # <- for read in parser(track)

  total_reads = 0; unique_reads = 0
  keys = info.keys()
  keys = sorted(keys, key = lambda (c): chrsort(c))
  
  tbl = []
  for c in keys :
    tbl.append([c, info[c]['Unique reads'], info[c]['Total reads']])
    total_reads  += info[c]['Total reads']
    unique_reads += info[c]['Unique reads']
  logging.info("Chromosome name, Unique reads, Total reads:")
  logging.info(beautiful_table(tbl))

  mean_length = 0
  for l in length_hist :
    mean_length += l * length_hist[l]
  mean_length = mean_length/total_reads

  msg = "Average read length: {}"
  logging.info(msg.format(mean_length))

  drate = round((1 - float(unique_reads)/float(total_reads)) * 100, 1)
  msg = "\nLibrary depth\n  Duplication rate:  {}%\n  Total reads:       {}\n  Unique reads:      {}"
  logging.info(msg.format(drate, total_reads, unique_reads))
  
  notes = [
    [99 , "  - Reads mapped in proper pair. Mate reverse strand, first in pair:  {}"],
    [147, "  - Reads mapped in proper pair. Read reverse strand, second in pair: {}"],
    [83 , "  - Reads mapped in proper pair. Read reverse strand, first in pair:  {}"],
    [163, "  - Reads mapped in proper pair. Mate reverse strand, second in pair: {}"],
  			 
    [97 , "  - Mate reverse strand, first in pair:                               {}"],
    [161, "  - Mate reverse strand, second in pair:                              {}"],
    [81 , "  - Read reverse strand, first in pair:                               {}"],
    [145, "  - Read reverse strand, second in pair:                              {}"],
  			 
    [113, "  - Mate reverse strand, Read reverse strand, first in pair:          {}"],
    [177, "  - Mate reverse strand, Read reverse strand, second in pair:         {}"],
    [65 , "  - First in pair:                                                    {}"],
    [129, "  - Second in pair:                                                   {}"],
  			 
    [73 , "  - Mate unmapped, first in pair:                                     {}"],
    [137, "  - Mate unmapped, second in pair:                                    {}"],
    [89 , "  - Mate unmapped, read reverse strand, first in pair:                {}"],
    [153, "  - Mate unmapped, read reverse strand, second in pair:               {}"]
  ]

  def paired() :
    for x in notes :
      if x[0] in reads : return True
    return False

  logging.info("\nStrand symmetry")
  fragment_size = fragmentsize
  
  if paired() :
    if fragment_size == 0 : 
      fragment_size = distance['sum']/distance['count'] + mean_length
    for key, msg in notes :
      logging.info(msg.format(reads[key] if key in reads else 0))
  else :
    if fragment_size == 0 : 
      fragment_size = 250
    logging.info("  [+] " + str(reads[0]))
    logging.info("  [-] " + str(reads[16]))

  logging.info("\nFragment size: " + str(fragment_size))
  logging.info("")
  
  effective_len = get_gms(info, mean_length, gms) * sum(track.chromosome_lengths)
  plambda = count_lambda(unique_reads, args.window, effective_len)

  logging.info("")
  logging.info("Genome Length:           {}".format(sum(track.chromosome_lengths)))
  logging.info("Effective genome Length: {}".format(effective_len))

  return [data, mean_length, fragment_size, plambda, total_reads, effective_len]


# ---------------------------------------------------------------------------- #
def windows(data, length, window_size, gap_size):
  keys = sorted(data.keys(), key = lambda (c): chrsort(c))
  tbl = []; eligible = 0; gaps = [0,0,0,0]
  for c in keys :
    wlist = array.array('l', [0])
    last_init = -max_window
    last_w_init_x = 0
    chr_windows = 0
    for read in data[c] :
      strand, init = read%1000, read/1000
      if init == last_init : continue
      gp = (init - last_init)/window_size
      if gp <= 3 : gaps[gp] += 1

      w_init = init/window_size * window_size
      if last_init + window_size + gap_size > init - window_size :
        k = 1
        while wlist[-1]/max_window < w_init :
          wlist.append((last_w_init_x + k * window_size) * max_window + 0)
          k += 1
      if wlist[-1]/max_window == w_init :
        wlist[-1] += 1
        chr_windows += 1
      else :
        wlist.append(w_init * max_window + 1)
        chr_windows += 1
      last_init = init
      last_w_init_x = last_init/window_size * window_size
    tbl.append([c, chr_windows])
    eligible += chr_windows
    data[c] = wlist

  msg = "Total eligible windows of {}bp with allowed gap size {}bp: {}"
  logging.info(msg.format(window_size, gap_size, chr_windows))

  msg = "Chromosome name, Eligible windows:\n{}"
  logging.info(msg.format(beautiful_table(tbl)))

  msg = "Gap size count:"
  for i in range(4) :
    msg += "\n  {:>3} - {:>3}bp: {}".format(i * window_size + 1, (i + 1) * window_size, gaps[i])
  logging.info(msg)

  return data


# ---------------------------------------------------------------------------- #
def islands(wlist, l0, plambda, window_size, threshold, resultf):
  f = open(resultf, 'w+')
  islands = 0; coverage = 0; reads_scores = {}

  def score(reads):
    if reads <= l0 : return 0
    t = scipy.stats.poisson.pmf(reads, plambda)
    return 1000 if t < 1e-320 else -numpy.log(t)

  def new_island(init, reads):
    return { 
      'from'  : init,
      'to'    : init + window_size,
      'score' : reads_scores[reads],
      'reads' : reads, 
      'count' : 1, 
      'gaps'  : 0
    }

  def write(chromosome, e, islands) :
    if e['score'] < threshold : return 0, 0
    f.write(chromosome +'\t' + str(e['from']) +'\t' + str(e['to'])+'\t' 'island_' + str(islands) +'\t' + str(e['score']) + '\n')
    return 1, (e['to'] - e['from'])

  for c in wlist :
    island = False
    for w in wlist[c] :
      reads, init = w%max_window, w/max_window
      if reads not in reads_scores : 
        reads_scores[reads] = score(reads)
      if not island :
        island = new_island(init, reads)
      else :
        # Same island
        if init == island['to'] :
          island['to'] += window_size
          island['count'] += 1
          island['reads'] += reads
          island['score'] += reads_scores[reads]
          if reads == 0 : island['gaps'] += 1
        # Other island
        else :
          i, cov = write(c, island, islands)
          islands += i; coverage += cov
          island = new_island(init, reads)
    # <- end for
    if island :
      i, cov = write(c, island, islands)
      islands += i; coverage += cov
  # <- end for
  f.close()
  return islands, coverage
from math import *
import scipy, numpy, scipy.stats

# ---------------------------------------------------------------------------- #
print 'Step 1 of 3: Counting unique reads'

track = bgunzip(args.track.name)
data, length, fragment, plambda, total_reads, effective_len = preparation(track, gms)
track.file_handle.close()

if args.window > max_window : args.window = max_window
if args.window < 10 : args.window = 10

pvalue = args.pvalue
if pvalue > 1 or pvalue <= 0 : pvalue = 0.2
l0 = scipy.stats.poisson.ppf(1 - pvalue, plambda)

msg = "Window read threshold:   {}\n" + \
      "i.e. {} is minimum number of reads in window to consider\n" + \
      "this window `eligible` with Poisson distribution p-value {}\n"
logging.info(msg.format(l0, l0, pvalue))

# ---------------------------------------------------------------------------- #

print 'Step 2 of 3: Making window list'

if args.window < 1 : args.window = 1
wlist = windows(data, length, args.window, gap_size)

# ---------------------------------------------------------------------------- #

print 'Step 3 of 3: Writing found islands'

if threshold > 0 :
  logging.info("The score threshold is: {}".format(threshold))
else :
  e_value = 100.0; bin_size = 0.001
  bg = Island_threshold(total_reads, args.window, gap_size, pvalue, effective_len, bin_size, e_value)
  threshold = bg.threshold
  logging.info("The score threshold is: {} (auto define)".format(threshold))

found, coverage = islands(wlist, l0, plambda, args.window, threshold, resultf)
coverage_txt = str(coverage) + ' bp'
if coverage > 1000000 :
  coverage_txt = str(float(coverage)/1000000) + ' Mbp (' + coverage_txt + ')'
logging.info("Coverage: {}".format(coverage_txt))
logging.info("Islands found: {}".format(found))

msg = "Done.\nIslands found:    {}\nOutput file name: {}\nLog file name:    {}"
print msg.format(found, resultf, logfile)

logging.info(('\n ').join([
  "Output file:",
  "1. Chromosome name",
  "2. Island start",
  "3. Island end",
  "4. Island name",
  "4. Island score"
]))

msg = "\nFinished. Elapsed time, seconds: {}"
logging.info(msg.format(round(time.time() - startTime, 2)))
logging.info("")

